{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527d69a5-b150-459f-a081-73c9064a54ed",
   "metadata": {},
   "source": [
    "# Phase 0: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f606aa-be08-4093-8b7c-619b127ae224",
   "metadata": {},
   "source": [
    "### Set up ChromeDriver with selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ca9a60-2c8f-42c3-a763-88a41d1d6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eadada-af17-401a-8a8f-8b513c97a074",
   "metadata": {},
   "source": [
    "### Navigate ChromeDriver to LinkedIn log-in page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a8619a-8c3e-4014-a874-2d34f940adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# Navigate to the LinkedIn login page\n",
    "driver.get('https://www.linkedin.com/login')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815bb47-4bf6-45c4-8da0-1c7f12d052d6",
   "metadata": {},
   "source": [
    "### Log-in to LinkedIn with account credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f0317-49be-4cb9-b229-feb82df62cbe",
   "metadata": {},
   "source": [
    "- Read Log-in details from external txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc653c3-b49a-4f85-a6ab-4853d3a74755",
   "metadata": {},
   "outputs": [],
   "source": [
    "login_txt = open('LinkedIn - Logging Details.txt', 'r')\n",
    "MY_USERNAME = login_txt.readline().replace('Username: ', '').replace('\\n', '')\n",
    "MY_PASSWORD = login_txt.readline().replace('Password: ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb94e276-5324-417c-9e53-b4117984a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your email address and password\n",
    "driver.find_element(By.ID, 'username').send_keys(MY_USERNAME)\n",
    "driver.find_element(By.ID, 'password').send_keys(MY_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10baed88-2795-4cda-850e-c7ae96ddf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the login form\n",
    "driver.find_element(By.CSS_SELECTOR, '.login__form_action_container button').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eba356-0d74-43c6-8905-2ac3d0c320db",
   "metadata": {},
   "source": [
    "### Navigate to saved LinkedIn jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb53425e-ded5-405e-8a8c-3166a1fe9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBS_URL = 'https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED'\n",
    "#driver.get(JOBS_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdb5d8-b234-4816-9245-3fc95df71007",
   "metadata": {},
   "source": [
    "### Use BeautifulSoup to get source content of jobs page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655585e6-aaba-48f2-b2a4-32a6cbf9d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05501fd8-310a-4783-8238-151c45ade301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "# Parse the HTML using Beautiful Soup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3973b-2316-403f-b47a-85f8bcd666d1",
   "metadata": {},
   "source": [
    "- Close ChromeDriver once done scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354d804a-0c8c-4e72-b93d-b10a94206509",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288bf23-9120-4a52-8f2e-6aacf3c23a4a",
   "metadata": {},
   "source": [
    "- Fetch all information on saved jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbbcca6f-552c-4c16-a1bd-b03249a66b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li class=\"reusable-search__result-container\">\n",
       "<!-- --><!-- -->\n",
       "<div class=\"LPKKpHLTVmvhcAuVeGRdqmzEouqLVTRJFMpI\" data-chameleon-result-urn=\"urn:li:fsd_jobPosting:3803021338\" data-view-name=\"search-entity-result-universal-template\">\n",
       "<div class=\"linked-area flex-1 cursor-pointer\">\n",
       "<div class=\"QObBLEvMEqbGOrNtcUZdRvpvJcjOQKhljNvA\">\n",
       "<div class=\"entity-result__universal-image\">\n",
       "<div class=\"display-flex align-items-center\">\n",
       "<!-- -->\n",
       "<a aria-hidden=\"true\" class=\"app-aware-link scale-down\" data-test-app-aware-link=\"\" href=\"https://www.linkedin.com/jobs/view/3803021338/?refId=0b4f4200-cf2a-40c5-ba62-e57d19a3d7f0&amp;trackingId=1FiBZR7WQJ%2BusIHRlJ27%2FQ%3D%3D&amp;trk=flagship3_job_home_savedjobs\" tabindex=\"-1\">\n",
       "<div class=\"ivm-image-view-model\">\n",
       "<div class=\"ivm-view-attr__img-wrapper display-flex\">\n",
       "<!-- --> <img alt=\"Volvo Group\" class=\"ivm-view-attr__img--centered EntityPhoto-square-3 evi-image lazy-image ember-view\" height=\"48\" id=\"ember33\" loading=\"lazy\" src=\"https://media.licdn.com/dms/image/C4D0BAQF6VxeKGI-lyg/company-logo_100_100/0/1632477690193/volvo_group_logo?e=1714003200&amp;v=beta&amp;t=ebVCo8BU42prE8NLN7pjYFxyW8ZX-u9sYq_CCEpawmg\" width=\"48\"/>\n",
       "</div>\n",
       "</div>\n",
       "</a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"PofMLJLYCNPCBOUhmySedBKgvnPKQNvZyexs entity-result__divider pt3 pb3 t-12 t-black--light\">\n",
       "<div class=\"mb1\">\n",
       "<div class=\"t-roman t-sans\">\n",
       "<div class=\"display-flex\">\n",
       "<span class=\"entity-result__title-line entity-result__title-line--2-lines\">\n",
       "<span class=\"entity-result__title-text t-16\">\n",
       "<a class=\"app-aware-link\" data-test-app-aware-link=\"\" href=\"https://www.linkedin.com/jobs/view/3803021338/?refId=0b4f4200-cf2a-40c5-ba62-e57d19a3d7f0&amp;trackingId=1FiBZR7WQJ%2BusIHRlJ27%2FQ%3D%3D&amp;trk=flagship3_job_home_savedjobs\">\n",
       "<!-- -->Professional Data Analyst<!-- -->\n",
       "</a>\n",
       "<!-- --> </span>\n",
       "</span>\n",
       "<!-- --> </div>\n",
       "</div>\n",
       "<div class=\"entity-result__primary-subtitle t-14 t-black t-normal\">\n",
       "<!-- -->Volvo Group<!-- -->\n",
       "</div>\n",
       "<div class=\"entity-result__secondary-subtitle t-14 t-normal\">\n",
       "<!-- -->Wrocław<!-- -->\n",
       "</div>\n",
       "</div>\n",
       "<!-- -->\n",
       "<!-- -->\n",
       "<div class=\"entity-result__insights t-12\">\n",
       "<div class=\"workflow-posted-jobs__jobs-insight\">\n",
       "<!-- --><!-- -->\n",
       "<div class=\"reusable-search-simple-insight\">\n",
       "<!-- --> <div class=\"reusable-search-simple-insight__text-container\">\n",
       "<span class=\"reusable-search-simple-insight__text reusable-search-simple-insight__text--small\">\n",
       "<span><span class=\"tvm__text tvm__text--positive\"><span> <li-icon aria-hidden=\"true\" class=\"v-align-bottom\" size=\"small\" type=\"radar-screen\"><svg data-supported-dps=\"16x16\" fill=\"currentColor\" focusable=\"false\" height=\"16\" viewbox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<path d=\"M13.13 8a5.14 5.14 0 11-2.23-4.22L8.58 6.1A2 2 0 008 6a2 2 0 102 2 2 2 0 00-.09-.57l3.68-3.67s-.34-.41-.63-.71-.7-.62-.7-.62A7 7 0 1015 8h-1.87z\"></path>\n",
       "</svg></li-icon>\n",
       "</span></span></span><span class=\"white-space-pre\"> </span>Actively recruiting<!-- -->\n",
       "</span>\n",
       "<!-- --> </div>\n",
       "</div>\n",
       "<div class=\"reusable-search-simple-insight reusable-search-simple-insight--subsequent\">\n",
       "<!-- --> <div class=\"reusable-search-simple-insight__text-container\">\n",
       "<span class=\"reusable-search-simple-insight__text reusable-search-simple-insight__text--small\">\n",
       "<!-- -->Posted 3d ago<!-- -->\n",
       "</span>\n",
       "<!-- --> </div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"entity-result__actions entity-result__divider\">\n",
       "<div class=\"entity-result__actions-overflow-menu-dropdown\">\n",
       "<div class=\"artdeco-dropdown artdeco-dropdown--placement-bottom artdeco-dropdown--justification-right ember-view\" id=\"ember35\">\n",
       "<button aria-expanded=\"false\" aria-label=\"Click to take more actions on Professional Data Analyst\" class=\"artdeco-dropdown__trigger artdeco-dropdown__trigger--placement-bottom ember-view entity-result__overflow-actions-trigger-ember34 artdeco-button artdeco-button--2 artdeco-button--tertiary artdeco-button--circle artdeco-button--muted\" id=\"ember36\" tabindex=\"0\" type=\"button\">\n",
       "<svg aria-hidden=\"true\" data-supported-dps=\"24x24\" data-test-icon=\"overflow-web-ios-medium\" height=\"24\" role=\"none\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<!-- -->\n",
       "<use height=\"24\" href=\"#overflow-web-ios-medium\" width=\"24\"></use>\n",
       "</svg>\n",
       "<!-- --></button>\n",
       "<div aria-hidden=\"true\" aria-label=\"Click to take more actions on Professional Data Analyst\" class=\"artdeco-dropdown__content artdeco-dropdown--is-dropdown-element artdeco-dropdown__content--has-arrow artdeco-dropdown__content--arrow-right artdeco-dropdown__content--justification-right artdeco-dropdown__content--placement-bottom ember-view entity-result__overflow-actions-menu\" id=\"ember37\" tabindex=\"-1\"><!-- --></div>\n",
       "</div>\n",
       "<div>\n",
       "<!-- -->\n",
       "</div>\n",
       "<!-- -->\n",
       "<!-- -->\n",
       "<!-- -->\n",
       "<!-- -->\n",
       "</div>\n",
       "<!-- --> </div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</li>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('li', {'class': 'reusable-search__result-container'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00893f-b439-41e0-91ab-4d929bb0fe51",
   "metadata": {},
   "source": [
    "- Now, it would be good to write a function that takes an instance of job and returns the following:\n",
    "\n",
    "> Job Title (Position)\n",
    ">\n",
    "> Job Company\n",
    ">\n",
    "> Job Location\n",
    ">\n",
    "> Job Status (actively recruiting, etc)\n",
    ">\n",
    "> Posted Date (we need to convert this to proper timestamp from string [eg. Posted 12h ago])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f74dc8-103b-463c-859f-2ec75098902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def jobmatch_get_job_details(job_html):\n",
    "\n",
    "    # Fetch only text from the job html code\n",
    "    job_text = job_html.get_text()\n",
    "    # Replace '\\n' tag with ';' so it's easier to return instances of proper text (; is not expected to be used anywere in job parameters)\n",
    "    job_text = job_text.replace('\\n', ';')\n",
    "    # Compile regex pattern to filter out '-' symbols\n",
    "    pattern = r'(?<=;)([^;]+)(?=;)'\n",
    "    job_pars = re.findall(pattern, job_text)\n",
    "    # Remove reduntant whitespaves left after treating bs4.Tag\n",
    "    out = [i for i in job_pars if not i.isspace()]\n",
    "\n",
    "    # Sometimes jobs don't have info on status, so we'll have to handle that as well\n",
    "    if len(out) == 5:\n",
    "        return {'Position' : out[0], 'Company' : out[1], 'Location' : out[2], 'Status' : out[3], 'Posted' : out[4].replace('Posted ', '')}\n",
    "    else:\n",
    "        return {'Position' : out[0], 'Company' : out[1], 'Location' : out[2], 'Status' : 'N/A', 'Posted' : out[3].replace('Posted ', '')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2bb9c2e-32a9-49a4-a2a6-fa2664c3d359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Position': 'ML Engineer / Data Scientist',\n",
       " 'Company': 'Zurich Insurance',\n",
       " 'Location': 'Cracow (Hybrid)',\n",
       " 'Status': ' Actively recruiting',\n",
       " 'Posted': '2w ago'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = soup.find_all('li', {'class': 'reusable-search__result-container'})[5]\n",
    "jobmatch_get_job_details(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70501a42-db40-4f61-93f6-937ec93b1a7a",
   "metadata": {},
   "source": [
    "- Now, let's collect this info for all companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a868a83-d042-480c-b95b-712508469b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job_details_table = [jobmatch_get_job_details(i) for i in soup.find_all('li', {'class': 'reusable-search__result-container'})]\n",
    "job_details_df = pd.DataFrame.from_dict(job_details_table)\n",
    "job_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655213c9-f27c-4d86-a9d3-f4b65ba6a3b5",
   "metadata": {},
   "source": [
    "- Since we will use this table in future, let's convert the posted column to proper timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "becdc40d-5fda-4ac5-8ca6-ea754f1feaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def convert_time_lag(row):\n",
    "    # Compile pattern to search for 'Nd/h ago' patter in Posted column\n",
    "    match = re.match(r'(\\d+)([dh])\\s+ago', row['Posted'])\n",
    "    # If matched\n",
    "    if match:\n",
    "        # Split the results to two groups - number of days/hours and time unit\n",
    "        value, unit = int(match.group(1)), match.group(2)\n",
    "        # If number of days specified\n",
    "        if unit == 'd':\n",
    "            return pd.to_datetime(datetime.now() - timedelta(days=value))\n",
    "        # If number of hours specified\n",
    "        elif unit == 'h':\n",
    "            return pd.to_datetime(datetime.now() - timedelta(hours=value))\n",
    "    # If the pattern wasn't matched at all return NaN\n",
    "    return pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5da7d2-7daf-4bb5-83f4-2d147285ef1d",
   "metadata": {},
   "source": [
    "- We probably won't need intra-day date precision, but will leave it for now in case of further project development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaaee9d-dbc5-4299-922a-ece58f1ea859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Date Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professional Data Analyst</td>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>Wrocław</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:26.308786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Analyst with Python</td>\n",
       "      <td>Unilever</td>\n",
       "      <td>Warsaw (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.317035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst in ESG Team</td>\n",
       "      <td>ING Hubs Poland</td>\n",
       "      <td>Warsaw Metropolitan Area (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.318015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Scientist (m/w/d)</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Berlin (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>2024-01-19 11:44:26.318015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Validator Quantitative Analyst MRMC US</td>\n",
       "      <td>UBS</td>\n",
       "      <td>Cracow (On-site)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>2024-01-18 11:44:26.318015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML Engineer / Data Scientist</td>\n",
       "      <td>Zurich Insurance</td>\n",
       "      <td>Cracow (Hybrid)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>2w ago</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consultant (Senior) for Data Analytics &amp; Data ...</td>\n",
       "      <td>BearingPoint</td>\n",
       "      <td>Prague, Czechia (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Generative AI</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Prague (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:26.319021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - 100% Remoto</td>\n",
       "      <td>Walters People</td>\n",
       "      <td>Barcelona (Remote)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.319021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Planning Data Scientist - Consultant</td>\n",
       "      <td>Accenture España</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.319021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position           Company  \\\n",
       "0                          Professional Data Analyst       Volvo Group   \n",
       "1                    Junior Data Analyst with Python          Unilever   \n",
       "2                           Data Analyst in ESG Team   ING Hubs Poland   \n",
       "3                 Machine Learning Scientist (m/w/d)             Bayer   \n",
       "4       Model Validator Quantitative Analyst MRMC US               UBS   \n",
       "5                       ML Engineer / Data Scientist  Zurich Insurance   \n",
       "6  Consultant (Senior) for Data Analytics & Data ...      BearingPoint   \n",
       "7                     Data Scientist - Generative AI               IBM   \n",
       "8                       Data Scientist - 100% Remoto    Walters People   \n",
       "9               Planning Data Scientist - Consultant  Accenture España   \n",
       "\n",
       "                            Location                Status  \\\n",
       "0                            Wrocław   Actively recruiting   \n",
       "1                   Warsaw (On-site)   Actively recruiting   \n",
       "2  Warsaw Metropolitan Area (Hybrid)                   N/A   \n",
       "3                   Berlin (On-site)   Actively recruiting   \n",
       "4                   Cracow (On-site)                   N/A   \n",
       "5                    Cracow (Hybrid)   Actively recruiting   \n",
       "6           Prague, Czechia (Hybrid)                   N/A   \n",
       "7                   Prague (On-site)   Actively recruiting   \n",
       "8                 Barcelona (Remote)   Actively recruiting   \n",
       "9                          Barcelona   Actively recruiting   \n",
       "\n",
       "                 Posted                Date Posted  \n",
       "0                3d ago 2024-01-17 11:44:26.308786  \n",
       "1                4d ago 2024-01-16 11:44:26.317035  \n",
       "2                4d ago 2024-01-16 11:44:26.318015  \n",
       "3                1d ago 2024-01-19 11:44:26.318015  \n",
       "4                2d ago 2024-01-18 11:44:26.318015  \n",
       "5                2w ago                        NaT  \n",
       "6   Actively recruiting                        NaT  \n",
       "7                3d ago 2024-01-17 11:44:26.319021  \n",
       "8                4d ago 2024-01-16 11:44:26.319021  \n",
       "9                4d ago 2024-01-16 11:44:26.319021  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details_df['Date Posted'] = job_details_df.apply(convert_time_lag, axis=1)\n",
    "job_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437d294-b6b6-4cc4-b706-6df2e236707f",
   "metadata": {},
   "source": [
    "- Now that we have all useful job details, it would be nice to have their direct links as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8334fc68-c395-4286-bc70-377c8c6ba130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/view/3785362967/?refId=0b4f4200-cf2a-40c5-ba62-e57d19a3d7f0&trackingId=BYuIlq5PROKjl1ELImutkA%3D%3D&trk=flagship3_job_home_savedjobs'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.find('a', {'class': 'app-aware-link scale-down'}, href=True)['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f621a90-4736-400e-9400-44787b41e7f3",
   "metadata": {},
   "source": [
    "- Seems that it should be enough to just fetch first hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e556b287-05b8-42b0-9fca-d9204f96b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobmatch_get_job_link(job_html):\n",
    "    return job_html.find('a', {'class': 'app-aware-link scale-down'}, href=True)['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0afe8d-2b18-4802-af87-75493f1a72ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Hyperlink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professional Data Analyst</td>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>Wrocław</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:26.308786</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3803021338/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Analyst with Python</td>\n",
       "      <td>Unilever</td>\n",
       "      <td>Warsaw (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.317035</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805491270/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst in ESG Team</td>\n",
       "      <td>ING Hubs Poland</td>\n",
       "      <td>Warsaw Metropolitan Area (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.318015</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805428308/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Scientist (m/w/d)</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Berlin (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>2024-01-19 11:44:26.318015</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3809397054/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Validator Quantitative Analyst MRMC US</td>\n",
       "      <td>UBS</td>\n",
       "      <td>Cracow (On-site)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>2024-01-18 11:44:26.318015</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3808472757/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML Engineer / Data Scientist</td>\n",
       "      <td>Zurich Insurance</td>\n",
       "      <td>Cracow (Hybrid)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>2w ago</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3785362967/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consultant (Senior) for Data Analytics &amp; Data ...</td>\n",
       "      <td>BearingPoint</td>\n",
       "      <td>Prague, Czechia (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3715499136/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Generative AI</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Prague (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:26.319021</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3803082749/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - 100% Remoto</td>\n",
       "      <td>Walters People</td>\n",
       "      <td>Barcelona (Remote)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.319021</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805442679/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Planning Data Scientist - Consultant</td>\n",
       "      <td>Accenture España</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:26.319021</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3775612118/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position           Company  \\\n",
       "0                          Professional Data Analyst       Volvo Group   \n",
       "1                    Junior Data Analyst with Python          Unilever   \n",
       "2                           Data Analyst in ESG Team   ING Hubs Poland   \n",
       "3                 Machine Learning Scientist (m/w/d)             Bayer   \n",
       "4       Model Validator Quantitative Analyst MRMC US               UBS   \n",
       "5                       ML Engineer / Data Scientist  Zurich Insurance   \n",
       "6  Consultant (Senior) for Data Analytics & Data ...      BearingPoint   \n",
       "7                     Data Scientist - Generative AI               IBM   \n",
       "8                       Data Scientist - 100% Remoto    Walters People   \n",
       "9               Planning Data Scientist - Consultant  Accenture España   \n",
       "\n",
       "                            Location                Status  \\\n",
       "0                            Wrocław   Actively recruiting   \n",
       "1                   Warsaw (On-site)   Actively recruiting   \n",
       "2  Warsaw Metropolitan Area (Hybrid)                   N/A   \n",
       "3                   Berlin (On-site)   Actively recruiting   \n",
       "4                   Cracow (On-site)                   N/A   \n",
       "5                    Cracow (Hybrid)   Actively recruiting   \n",
       "6           Prague, Czechia (Hybrid)                   N/A   \n",
       "7                   Prague (On-site)   Actively recruiting   \n",
       "8                 Barcelona (Remote)   Actively recruiting   \n",
       "9                          Barcelona   Actively recruiting   \n",
       "\n",
       "                 Posted                Date Posted  \\\n",
       "0                3d ago 2024-01-17 11:44:26.308786   \n",
       "1                4d ago 2024-01-16 11:44:26.317035   \n",
       "2                4d ago 2024-01-16 11:44:26.318015   \n",
       "3                1d ago 2024-01-19 11:44:26.318015   \n",
       "4                2d ago 2024-01-18 11:44:26.318015   \n",
       "5                2w ago                        NaT   \n",
       "6   Actively recruiting                        NaT   \n",
       "7                3d ago 2024-01-17 11:44:26.319021   \n",
       "8                4d ago 2024-01-16 11:44:26.319021   \n",
       "9                4d ago 2024-01-16 11:44:26.319021   \n",
       "\n",
       "                                           Hyperlink  \n",
       "0  https://www.linkedin.com/jobs/view/3803021338/...  \n",
       "1  https://www.linkedin.com/jobs/view/3805491270/...  \n",
       "2  https://www.linkedin.com/jobs/view/3805428308/...  \n",
       "3  https://www.linkedin.com/jobs/view/3809397054/...  \n",
       "4  https://www.linkedin.com/jobs/view/3808472757/...  \n",
       "5  https://www.linkedin.com/jobs/view/3785362967/...  \n",
       "6  https://www.linkedin.com/jobs/view/3715499136/...  \n",
       "7  https://www.linkedin.com/jobs/view/3803082749/...  \n",
       "8  https://www.linkedin.com/jobs/view/3805442679/...  \n",
       "9  https://www.linkedin.com/jobs/view/3775612118/...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_details_df['Hyperlink'] = [jobmatch_get_job_link(i) for i in soup.find_all('li', {'class': 'reusable-search__result-container'})]\n",
    "job_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77185220-f960-42b6-b391-4c1d95910f0f",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b6f55-f570-405c-97cf-aa5ee3b93994",
   "metadata": {},
   "source": [
    "> Read all jobs on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "660e70bd-f98a-40fc-8171-31e8c5422f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_page = soup.find_all('li', {'class': 'reusable-search__result-container'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a24be-e34e-4d0c-8068-7cf42ceea47f",
   "metadata": {},
   "source": [
    "> Compile DataFrame with all required entry for job on current page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b22e88b9-ccdb-4943-a94b-c42ebb0a164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobmatch_page_tab(page):\n",
    "\n",
    "    # Read basic details of each job on current page\n",
    "    job_details = [jobmatch_get_job_details(i) for i in page]\n",
    "    job_details = pd.DataFrame.from_dict(job_details)\n",
    "\n",
    "    # Convert posted time lag to TimeStamp\n",
    "    job_details['Date Posted'] = job_details.apply(convert_time_lag, axis=1)\n",
    "\n",
    "    # Attach page URLs\n",
    "    job_details['URL'] = [jobmatch_get_job_link(i) for i in page]\n",
    "\n",
    "    return job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b4ce618-7f58-4609-8ad5-55d32ad166f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professional Data Analyst</td>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>Wrocław</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:57.473810</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3803021338/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Analyst with Python</td>\n",
       "      <td>Unilever</td>\n",
       "      <td>Warsaw (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:57.475804</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805491270/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst in ESG Team</td>\n",
       "      <td>ING Hubs Poland</td>\n",
       "      <td>Warsaw Metropolitan Area (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:57.475804</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805428308/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Scientist (m/w/d)</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Berlin (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>2024-01-19 11:44:57.476798</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3809397054/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model Validator Quantitative Analyst MRMC US</td>\n",
       "      <td>UBS</td>\n",
       "      <td>Cracow (On-site)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>2024-01-18 11:44:57.477795</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3808472757/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML Engineer / Data Scientist</td>\n",
       "      <td>Zurich Insurance</td>\n",
       "      <td>Cracow (Hybrid)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>2w ago</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3785362967/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consultant (Senior) for Data Analytics &amp; Data ...</td>\n",
       "      <td>BearingPoint</td>\n",
       "      <td>Prague, Czechia (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3715499136/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Generative AI</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Prague (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>2024-01-17 11:44:57.477795</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3803082749/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - 100% Remoto</td>\n",
       "      <td>Walters People</td>\n",
       "      <td>Barcelona (Remote)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:57.478832</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805442679/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Planning Data Scientist - Consultant</td>\n",
       "      <td>Accenture España</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 11:44:57.479829</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3775612118/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position           Company  \\\n",
       "0                          Professional Data Analyst       Volvo Group   \n",
       "1                    Junior Data Analyst with Python          Unilever   \n",
       "2                           Data Analyst in ESG Team   ING Hubs Poland   \n",
       "3                 Machine Learning Scientist (m/w/d)             Bayer   \n",
       "4       Model Validator Quantitative Analyst MRMC US               UBS   \n",
       "5                       ML Engineer / Data Scientist  Zurich Insurance   \n",
       "6  Consultant (Senior) for Data Analytics & Data ...      BearingPoint   \n",
       "7                     Data Scientist - Generative AI               IBM   \n",
       "8                       Data Scientist - 100% Remoto    Walters People   \n",
       "9               Planning Data Scientist - Consultant  Accenture España   \n",
       "\n",
       "                            Location                Status  \\\n",
       "0                            Wrocław   Actively recruiting   \n",
       "1                   Warsaw (On-site)   Actively recruiting   \n",
       "2  Warsaw Metropolitan Area (Hybrid)                   N/A   \n",
       "3                   Berlin (On-site)   Actively recruiting   \n",
       "4                   Cracow (On-site)                   N/A   \n",
       "5                    Cracow (Hybrid)   Actively recruiting   \n",
       "6           Prague, Czechia (Hybrid)                   N/A   \n",
       "7                   Prague (On-site)   Actively recruiting   \n",
       "8                 Barcelona (Remote)   Actively recruiting   \n",
       "9                          Barcelona   Actively recruiting   \n",
       "\n",
       "                 Posted                Date Posted  \\\n",
       "0                3d ago 2024-01-17 11:44:57.473810   \n",
       "1                4d ago 2024-01-16 11:44:57.475804   \n",
       "2                4d ago 2024-01-16 11:44:57.475804   \n",
       "3                1d ago 2024-01-19 11:44:57.476798   \n",
       "4                2d ago 2024-01-18 11:44:57.477795   \n",
       "5                2w ago                        NaT   \n",
       "6   Actively recruiting                        NaT   \n",
       "7                3d ago 2024-01-17 11:44:57.477795   \n",
       "8                4d ago 2024-01-16 11:44:57.478832   \n",
       "9                4d ago 2024-01-16 11:44:57.479829   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.linkedin.com/jobs/view/3803021338/...  \n",
       "1  https://www.linkedin.com/jobs/view/3805491270/...  \n",
       "2  https://www.linkedin.com/jobs/view/3805428308/...  \n",
       "3  https://www.linkedin.com/jobs/view/3809397054/...  \n",
       "4  https://www.linkedin.com/jobs/view/3808472757/...  \n",
       "5  https://www.linkedin.com/jobs/view/3785362967/...  \n",
       "6  https://www.linkedin.com/jobs/view/3715499136/...  \n",
       "7  https://www.linkedin.com/jobs/view/3803082749/...  \n",
       "8  https://www.linkedin.com/jobs/view/3805442679/...  \n",
       "9  https://www.linkedin.com/jobs/view/3775612118/...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobmatch_page_tab(job_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e271da-1f25-4b4b-b985-e1fa3fd91378",
   "metadata": {},
   "source": [
    "- Now that we have a framework to compile a simple table from one job page, we will run the function on all pages of saved jobs\n",
    "- It looks like LinkeIn organizes their URLs in such a way that it's enough to add '&start=10' to go to next set of jobs from 'SAVED'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30676318-852a-445c-b480-e196fe5ed186",
   "metadata": {},
   "source": [
    "## Reading number of saved pages to scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5dc344-8235-4cfa-a019-15d5ff8c59e9",
   "metadata": {},
   "source": [
    "### FIXME - Fix reading the numebr of pages (read just the max index int in the CSS object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b74b6-b8e5-4e17-8a2b-106e407719cc",
   "metadata": {},
   "source": [
    "- The following HTML object contains all of numbers (and links) to indexes of job pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecece5a7-5c94-4fb7-90e4-5b2d83c0739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_number_obj = soup.find('ul', {'class' : 'artdeco-pagination__pages artdeco-pagination__pages--number'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca434fc-ee44-41de-ace6-adf3049db101",
   "metadata": {},
   "source": [
    "- If there are more than 10 pages, linked in will squeeze them with \"...\", therefore we will just read the last page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d44d750-c4d5-4077-a384-e7b5a16abdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of saved jobs pages found: 11\n"
     ]
    }
   ],
   "source": [
    "last_page_str = str(pages_number_obj.find_all('li')[-1].find('span')) # Find the number of last saved jobs page\n",
    "last_page_idx = int(re.findall(r'\\d+', last_page_str)[0]) # Read the number from <span> tag and convert it to number\n",
    "print(f'Number of saved jobs pages found: {last_page_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26c9cc-5596-4ac0-9ac8-88b7084ceef5",
   "metadata": {},
   "source": [
    "- Now we have to create a simple mechanism to compile URL for each job page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4305e964-7d39-4739-8d06-d7799af5a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=0\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=10\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=20\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=30\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=40\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=50\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=60\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=70\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=80\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=90\n",
      "https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED&start=100\n"
     ]
    }
   ],
   "source": [
    "saved_jobs_pages = []\n",
    "\n",
    "for i in range(last_page_idx):\n",
    "    p_url = JOBS_URL + f'&start={i*10}'\n",
    "    print(p_url)\n",
    "    saved_jobs_pages.append(p_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b815b5-abfd-4e9b-aeb8-22f341cd84b8",
   "metadata": {},
   "source": [
    "- Since each of URL is working fine (including the first 'reduntant' one) we will just use this to compile full table of saved jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d437ff-2853-42b8-a4ab-0f663e57c6db",
   "metadata": {},
   "source": [
    "- This concludes Tesing Phase, we can move on with 'production-ready' code for organizing the jobs in one table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0181877-fdbb-482e-bb20-64efadacbd5c",
   "metadata": {},
   "source": [
    "# Phase 1: Dataset of saved linked-in jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388a884-7d2b-4236-88d1-ce489aad30ee",
   "metadata": {},
   "source": [
    "## Constructing full job dataset from all saved pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb4dfdc4-d161-4390-a3f4-6b6e85c6d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "class JobMatch:\n",
    "    # Define global link to the saved jobs\n",
    "    JOBS_URL = 'https://www.linkedin.com/my-items/saved-jobs/?cardType=SAVED'\n",
    "\n",
    "    def __init__(self, username, password):\n",
    "\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "\n",
    "\n",
    "    def login(self):\n",
    "\n",
    "        print('JobMatch: Logging to linked-in, please wait...')\n",
    "    \n",
    "        self.driver = webdriver.Chrome()\n",
    "        time.sleep(2)\n",
    "        # Navigate to the LinkedIn login page\n",
    "        self.driver.get('https://www.linkedin.com/login')\n",
    "        # Wait unti lthe page loads\n",
    "        time.sleep(5)\n",
    "        # Enter your email address and password\n",
    "        self.driver.find_element(By.ID, 'username').send_keys(self.username)\n",
    "        time.sleep(1)\n",
    "        self.driver.find_element(By.ID, 'password').send_keys(self.password)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Submit the login form\n",
    "        self.driver.find_element(By.CSS_SELECTOR, '.login__form_action_container button').click()\n",
    "\n",
    "        ###TODO: Please add handling of the incorect log-in scenario\n",
    "        print('JobMatch: Log-in completed!')\n",
    "\n",
    "    def get_page_soup(self, page_url):\n",
    "\n",
    "        self.driver.get(page_url)\n",
    "        # Wait until the page is loaded properly\n",
    "        time.sleep(5)\n",
    "        # Get the page source\n",
    "        page_source = self.driver.page_source\n",
    "        # Parse the HTML using Beautiful Soup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        return soup\n",
    "\n",
    "    def get_n_job_pages(self):\n",
    "        \n",
    "        # Get the soup source of tha base page of saved jobs\n",
    "        base_soup = self.get_page_soup(JOBS_URL)\n",
    "        # Scan the source for pages index placeholder\n",
    "        pages_idx_obj = base_soup.find('ul', {'class' : 'artdeco-pagination__pages artdeco-pagination__pages--number'})\n",
    "        last_page_str = str(pages_idx_obj.find_all('li')[-1].find('span')) # Find the number of last saved jobs page\n",
    "        # Check how many jobs pages are there\n",
    "        n_job_pages = int(re.findall(r'\\d+', last_page_str)[0])\n",
    "\n",
    "        return int(n_job_pages)\n",
    "\n",
    "    def get_saved_pages_urls(self):\n",
    "\n",
    "        n_job_pages = self.get_n_job_pages()\n",
    "\n",
    "        pages_urls = []\n",
    "\n",
    "        for i in range(n_job_pages):\n",
    "            p_url = JOBS_URL + f'&start={i*10}'\n",
    "            pages_urls.append(p_url)\n",
    "\n",
    "        return pages_urls\n",
    "\n",
    "    def get_job_details(self, job_soup):\n",
    "        job_details = job_soup.find('div', class_=\"job-details-jobs-unified-top-card__primary-description-without-tagline mb2\").get_text().replace('\\n', '')\n",
    "        job_details = re.split(r'\\s·\\s', job_details)\n",
    "\n",
    "        job_position = job_soup.find('div', class_=\"display-flex justify-space-between flex-wrap\").get_text().replace('\\n', '').strip()\n",
    "        out = [job_position] + job_details\n",
    "        # Sometimes jobs don't have info on status, so we'll have to handle that as well\n",
    "        \n",
    "        return {'Position' : out[0], 'Company' : out[1], 'Location' : out[2], 'Posted' : out[3].replace('Posted ', ''), 'Status' : out[4]}\n",
    "\n",
    "    def convert_time_lag(self, row):\n",
    "        # Compile pattern to search for 'Nd/h ago' patter in Posted column\n",
    "        match = re.match(r'(\\d+)([dhwmo]{1,2})\\sago', row['Posted'])\n",
    "        # If matched\n",
    "        if match:\n",
    "            # Split the results to two groups - number of days/hours and time unit\n",
    "            value, unit = int(match.group(1)), match.group(2)\n",
    "            # If number of days specified\n",
    "            if unit == 'd':\n",
    "                return pd.to_datetime(datetime.now() - timedelta(days=value))\n",
    "            # If number of hours specified\n",
    "            elif unit == 'h':\n",
    "                return pd.to_datetime(datetime.now() - timedelta(hours=value))\n",
    "            # If number of weeks given\n",
    "            elif unit == 'w':\n",
    "                return pd.to_datetime(datetime.now() - timedelta(days=(value*7)))\n",
    "            # If number of months given\n",
    "            elif unit == 'mo':\n",
    "                return pd.to_datetime(datetime.now() - timedelta(days=(value*30)))\n",
    "        # If the pattern wasn't matched at all return NaN\n",
    "        return pd.NaT\n",
    "\n",
    "    def get_job_link(self, job_html):\n",
    "        return job_html.find('a', {'class': 'app-aware-link scale-down'}, href=True)['href']\n",
    "\n",
    "    def jobmatch_page_tab(self, page):\n",
    "\n",
    "        # Read basic details of each job on current page\n",
    "        job_details = [self.get_job_details(i) for i in page]\n",
    "        job_details = pd.DataFrame.from_dict(job_details)\n",
    "\n",
    "        # Convert posted time lag to TimeStamp\n",
    "        job_details['Date Posted'] = job_details.apply(self.convert_time_lag, axis=1)\n",
    "    \n",
    "        # Attach page URLs\n",
    "        job_details['URL'] = [self.get_job_link(i) for i in page]\n",
    "\n",
    "        return job_details\n",
    "\n",
    "    def compile_jobs_dataframe(self):\n",
    "        print('JobMatch: Compiling DataFrame with all saved Linke-in jobs, please wait..')\n",
    "\n",
    "        frames = []\n",
    "\n",
    "        saved_pages_urls = self.get_saved_pages_urls()\n",
    "        # For each pages of saved jobs in linkedin\n",
    "        for page_url in tqdm(saved_pages_urls, desc='Process'):\n",
    "            #print(f'Scanning job page no.{page_idx}..')\n",
    "            page_soup = self.get_page_soup(page_url)\n",
    "            job_page = page_soup.find_all('li', {'class': 'reusable-search__result-container'})\n",
    "            # Get the full data table for current page\n",
    "            frames.append(self.jobmatch_page_tab(job_page))\n",
    "\n",
    "        # Exit chrome session once all done\n",
    "        self.driver.quit()\n",
    "\n",
    "        print('JobMatch: DataFrame completed!')\n",
    "        # Concatenate the tables to one table and return it\n",
    "        return pd.concat(frames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b52fbd-962b-4478-be27-afc61a07d195",
   "metadata": {},
   "source": [
    "> Step 1: Initialize JobMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6393c8a2-c5e3-4ca1-a6c9-77c392ef2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_match = JobMatch(username = MY_USERNAME,\n",
    "                   password = MY_PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7fc8a7-4625-4707-b69d-1860e0075be3",
   "metadata": {},
   "source": [
    "> Step 2: Logging in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "553e953a-b636-4408-bb54-c139db6a8329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobMatch: Logging to linked-in, please wait...\n",
      "JobMatch: Log-in completed!\n"
     ]
    }
   ],
   "source": [
    "li_match.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471fa9fb-1829-4d66-80a8-66ebb2b7e35f",
   "metadata": {},
   "source": [
    "> Step 3: Construct table of characteristics for every job saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73660b3-92f0-46db-89c2-1f36478b79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = li_match.compile_jobs_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7447361b-8479-4d58-88e8-4d29c44e3f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gartner</td>\n",
       "      <td>Barcelona (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>2024-01-19 22:00:05.670473</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3809116486/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional Data Analyst</td>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>Wrocław</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>2024-01-16 22:00:05.670473</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3803021338/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Analyst with Python</td>\n",
       "      <td>Unilever</td>\n",
       "      <td>Warsaw (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>2024-01-15 22:00:05.670473</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805491270/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst in ESG Team</td>\n",
       "      <td>ING Hubs Poland</td>\n",
       "      <td>Warsaw Metropolitan Area (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>2024-01-15 22:00:05.670473</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3805428308/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Scientist (m/w/d)</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Berlin (On-site)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>2024-01-18 22:00:05.670473</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3809397054/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Applied LLM Researcher</td>\n",
       "      <td>Creative Chaos</td>\n",
       "      <td>Poland (Remote)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3736915128/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Senior Data Scientist (Advanced Analytics)</td>\n",
       "      <td>SoftServe</td>\n",
       "      <td>Poland (Remote)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>10h ago</td>\n",
       "      <td>2024-01-20 12:01:20.161897</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3731852302/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Data Scientist (Risk)</td>\n",
       "      <td>Revolut</td>\n",
       "      <td>Poland (Remote)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1w ago</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3723326089/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Consultant Quant</td>\n",
       "      <td>AWALEE CONSULTING by Canopee Group</td>\n",
       "      <td>Paris (Hybrid)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3725416038/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Machine Learning Scientist (They/She/He)</td>\n",
       "      <td>Glovo</td>\n",
       "      <td>Greater Barcelona Metropolitan Area (Hybrid)</td>\n",
       "      <td>Actively recruiting</td>\n",
       "      <td>1w ago</td>\n",
       "      <td>NaT</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3702367480/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Position  \\\n",
       "0                                Data Scientist   \n",
       "1                     Professional Data Analyst   \n",
       "2               Junior Data Analyst with Python   \n",
       "3                      Data Analyst in ESG Team   \n",
       "4            Machine Learning Scientist (m/w/d)   \n",
       "..                                          ...   \n",
       "98                       Applied LLM Researcher   \n",
       "99   Senior Data Scientist (Advanced Analytics)   \n",
       "100                       Data Scientist (Risk)   \n",
       "101                           Consultant Quant    \n",
       "102    Machine Learning Scientist (They/She/He)   \n",
       "\n",
       "                                Company  \\\n",
       "0                               Gartner   \n",
       "1                           Volvo Group   \n",
       "2                              Unilever   \n",
       "3                       ING Hubs Poland   \n",
       "4                                 Bayer   \n",
       "..                                  ...   \n",
       "98                       Creative Chaos   \n",
       "99                            SoftServe   \n",
       "100                             Revolut   \n",
       "101  AWALEE CONSULTING by Canopee Group   \n",
       "102                               Glovo   \n",
       "\n",
       "                                         Location                Status  \\\n",
       "0                             Barcelona (On-site)   Actively recruiting   \n",
       "1                                         Wrocław   Actively recruiting   \n",
       "2                                Warsaw (On-site)   Actively recruiting   \n",
       "3               Warsaw Metropolitan Area (Hybrid)                   N/A   \n",
       "4                                Berlin (On-site)   Actively recruiting   \n",
       "..                                            ...                   ...   \n",
       "98                                Poland (Remote)                   N/A   \n",
       "99                                Poland (Remote)   Actively recruiting   \n",
       "100                               Poland (Remote)   Actively recruiting   \n",
       "101                                Paris (Hybrid)                   N/A   \n",
       "102  Greater Barcelona Metropolitan Area (Hybrid)   Actively recruiting   \n",
       "\n",
       "                   Posted                Date Posted  \\\n",
       "0                  1d ago 2024-01-19 22:00:05.670473   \n",
       "1                  4d ago 2024-01-16 22:00:05.670473   \n",
       "2                  5d ago 2024-01-15 22:00:05.670473   \n",
       "3                  5d ago 2024-01-15 22:00:05.670473   \n",
       "4                  2d ago 2024-01-18 22:00:05.670473   \n",
       "..                    ...                        ...   \n",
       "98    Actively recruiting                        NaT   \n",
       "99                10h ago 2024-01-20 12:01:20.161897   \n",
       "100                1w ago                        NaT   \n",
       "101   Actively recruiting                        NaT   \n",
       "102                1w ago                        NaT   \n",
       "\n",
       "                                                   URL  \n",
       "0    https://www.linkedin.com/jobs/view/3809116486/...  \n",
       "1    https://www.linkedin.com/jobs/view/3803021338/...  \n",
       "2    https://www.linkedin.com/jobs/view/3805491270/...  \n",
       "3    https://www.linkedin.com/jobs/view/3805428308/...  \n",
       "4    https://www.linkedin.com/jobs/view/3809397054/...  \n",
       "..                                                 ...  \n",
       "98   https://www.linkedin.com/jobs/view/3736915128/...  \n",
       "99   https://www.linkedin.com/jobs/view/3731852302/...  \n",
       "100  https://www.linkedin.com/jobs/view/3723326089/...  \n",
       "101  https://www.linkedin.com/jobs/view/3725416038/...  \n",
       "102  https://www.linkedin.com/jobs/view/3702367480/...  \n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75641ce2-5635-4039-9fc9-a59b9e2ba1ac",
   "metadata": {},
   "source": [
    "- Let's save above table in csv file for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa22f606-b044-43d2-8b14-d95aea833936",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv('JobMatch - Saved Linked-in Jobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cde7e-5492-4abe-a764-5c4cc435ebd9",
   "metadata": {},
   "source": [
    "- Phase 1 is completed, now we have a nice table with all information required per each saved job\n",
    "- Now we can move to phase 2, quantifying how fell job fit candidate CV by using one of LLMs available "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
